---
title: "Global Baseline Estimate"
format: html
editor: visual
---

## Introduction
This project, I am analyzing a survey dataset containing movie ratings from 5 critics across 6 most recent popular movies. The dataset is sparse, meaning some of the critics have not seen or rated some of the movies. I will use this data to implement a Global Baseline Estimate recommendar system.

https://github.com/CiaraBonn12/Week-3-Data-607

## Approach
 The formula that is going to be used combines the group average with individual bias. This is a non-personalized recommendation strategy that predicts a rating based on three factors: the overall group average, the specific critic's rating behavior, and the movie's general popularity. The goal is also to use R to tidy my data, calculate the offsets for each movie and critic, and then fill in the blanks.

 ## Approach

The mathematical implementation will follow the formula:

$$\hat{r}_{u,i} = \mu + b_u + b_i$$



Where:
* $\hat{r}_{u,i}$ is the **Baseline Estimate** (the predicted rating)
* $\mu$ is the **Global Mean** (average of all ratings in the dataset)
* $b_u$ is the **User Bias** (how much a critic deviates from the average)
* $b_i$ is the **Item Bias** (how much a movie deviates from the average)

I will use `pivot_longer` to tidy the data into a long format so that R can perform group-level calculations on the ratings. I will calculate the **Item Bias** by determining how much a movieâ€™s average rating deviates from the global mean. I will calculate the **User Bias** by determining if a specific critic is generally more or less generous than the average.



## Challenges
I anticipate the "Cold Start" to be a problem because of the reviewers that have a few ratings. This makes the User Bias less stable. However, the GBE is specifically designed to handle this by falling back on the on the Global Mean and Movie popularity when specific user data is thin.